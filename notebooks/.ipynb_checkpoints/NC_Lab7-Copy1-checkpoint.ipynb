{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7: Recurrent Neural Networks\n",
    "\n",
    "Nick Chao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Selection\n",
    "\n",
    "Select a dataset similarly to lab one:text. That is, the dataset should be text data (or a time series sequence). In terms of generalization performance, it is helpful to have a large dataset of similar sized text documents. It is fine to perform binary classification or multi-class classification. The classification can be \"many-to-one\" or \"many-to-many\" sequence classification, whichever you feel more comfortable with. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparation (30 points total)\n",
    "[10 points] Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed). Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created).   \n",
    "\n",
    "[10 points] Choose and explain what metric(s) you will use to evaluate your algorithmâ€™s performance. You should give a detailed argument for why this (these) metric(s) are appropriate on your data. That is, why is the metric appropriate for the task (e.g., in terms of the business case for the task). Please note: rarely is accuracy the best evaluation metric to use. Think deeply about an appropriate measure of performance.\n",
    "\n",
    "[10 points] Choose the method you will use for dividing your data into training and testing (i.e., are you using Stratified 10-fold cross validation? Shuffle splits? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. Convince me that your cross validation method is a realistic mirroring of how an algorithm would be used in practice. \n",
    "\n",
    "#### Modeling (50 points total)\n",
    "[15 points] Investigate at least two different recurrent network architectures (perhaps LSTM and GRU). Be sure to use an embedding layer (pre-trained, from scratch, or both). Adjust hyper-parameters of the networks as needed to improve generalization performance. \n",
    "\n",
    "[15 points] Using the best RNN parameters and architecture, add a second recurrent chain to your RNN. The input to the second chain should be the output sequence of the first chain. Visualize the performance of training and validation sets versus the training iterations. \n",
    "\n",
    "[20 points] Use the method of cross validation and evaluation criteria that you argued for at the beginning of the lab. Visualize the results of all the RNNs you trained.  Use proper statistical comparison techniques to determine which method(s) is (are) superior.  \n",
    "\n",
    "#### Exceptional Work (10 points total)\n",
    "You have free reign to provide additional analyses.\n",
    "One idea (required for 7000 level students): Use t-SNE (or SVD) to visualize the word embeddings of a subset of words in your vocabulary. Try to interpret what each dimension reflects (in your own words). That is, try to explain what aspect of the language is encoded in the reduced dimensionality embedding. \n",
    "Another Idea (NOT required): Try to create a RNN for generating novel text. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset I will be using is video game reviews from Amazon. This dataset has approximately 231,780 reviews and is a k-core subset of the complete dataset. This data comes from the 5-score subset in which all users and items have at least 5 reviews. These reviews include ratings, text, and helpfulness votes. It also contains metadata related to the products.\n",
    "\n",
    "More information about the dataset can be found here: http://jmcauley.ucsd.edu/data/amazon/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviews have become increasingly more crucial in consumer purchases over the years. They are trusted by the public as they are written by the public. According to https://www.entrepreneur.com/article/253361, 70 percent of global consumers trust online reviews. Even more so, Amazon reviews are some of the most common destination for consumers to start researching their desired products. Without a doubt, online reviews are becoming more and more important in the global market. As reviews become more and more common during consumer research, so do ratings. \n",
    "\n",
    "Ratings are the first thing that consumers see when they begin their research and typically focus on the reviews of the polar ratings (5 stars vs 1 star). If there are enough of these polar ratings then a consumer may not even bother reading reviews as they trust the authors. This means that businesses must montior their products to see what consumers deem 5 star and what they deem to be 1 star. Knowing this information can help these businesses develop more consumer happy products or remediate a consumer's unhappy product experience. The better the rating for a product, the more likely it is a consumer will buy the product.\n",
    "\n",
    "Even though Amazon proivides a rating system for their consumer reviews, other sources do not. For example, relating to this dataset of video games, there are many sources where players can write reviews but do not provide a star rating. These type of reviews are helpful to consumers as they determine if a video game is worth purchasing or not. The goal of my prediction task is to see if it is possible to determine the rating of a review based on the text an author writes. As the ultimate goal of reading video game reviews is to either buy the game or not, this will be a binary classification task where a 5-star review is buy and a 1-star review is don't buy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependancies\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import keras\n",
    "import copy\n",
    "from sklearn import metrics as mt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import TimeDistributed, Dense, Activation, Input, Dropout\n",
    "from keras.layers import Embedding, Flatten, Merge, concatenate\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.layers import LSTM, GRU\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD, Adagrad, Adam, RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix, make_scorer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_json('../data/reviews_Video_Games_5.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 231780 entries, 0 to 231779\n",
      "Data columns (total 9 columns):\n",
      "asin              231780 non-null object\n",
      "helpful           231780 non-null object\n",
      "overall           231780 non-null int64\n",
      "reviewText        231780 non-null object\n",
      "reviewTime        231780 non-null object\n",
      "reviewerID        231780 non-null object\n",
      "reviewerName      228967 non-null object\n",
      "summary           231780 non-null object\n",
      "unixReviewTime    231780 non-null int64\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 17.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# lets take a look at the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0700099867</td>\n",
       "      <td>[8, 12]</td>\n",
       "      <td>1</td>\n",
       "      <td>Installing the game was a struggle (because of...</td>\n",
       "      <td>07 9, 2012</td>\n",
       "      <td>A2HD75EMZR8QLN</td>\n",
       "      <td>123</td>\n",
       "      <td>Pay to unlock content? I don't think so.</td>\n",
       "      <td>1341792000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0700099867</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>4</td>\n",
       "      <td>If you like rally cars get this game you will ...</td>\n",
       "      <td>06 30, 2013</td>\n",
       "      <td>A3UR8NLLY1ZHCX</td>\n",
       "      <td>Alejandro Henao \"Electronic Junky\"</td>\n",
       "      <td>Good rally game</td>\n",
       "      <td>1372550400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0700099867</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1st shipment received a book instead of the ga...</td>\n",
       "      <td>06 28, 2014</td>\n",
       "      <td>A1INA0F5CWW3J4</td>\n",
       "      <td>Amazon Shopper \"Mr.Repsol\"</td>\n",
       "      <td>Wrong key</td>\n",
       "      <td>1403913600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0700099867</td>\n",
       "      <td>[7, 10]</td>\n",
       "      <td>3</td>\n",
       "      <td>I got this version instead of the PS3 version,...</td>\n",
       "      <td>09 14, 2011</td>\n",
       "      <td>A1DLMTOTHQ4AST</td>\n",
       "      <td>ampgreen</td>\n",
       "      <td>awesome game, if it did not crash frequently !!</td>\n",
       "      <td>1315958400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0700099867</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>4</td>\n",
       "      <td>I had Dirt 2 on Xbox 360 and it was an okay ga...</td>\n",
       "      <td>06 14, 2011</td>\n",
       "      <td>A361M14PU2GUEG</td>\n",
       "      <td>Angry Ryan \"Ryan A. Forrest\"</td>\n",
       "      <td>DIRT 3</td>\n",
       "      <td>1308009600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  helpful  overall  \\\n",
       "0  0700099867  [8, 12]        1   \n",
       "1  0700099867   [0, 0]        4   \n",
       "2  0700099867   [0, 0]        1   \n",
       "3  0700099867  [7, 10]        3   \n",
       "4  0700099867   [2, 2]        4   \n",
       "\n",
       "                                          reviewText   reviewTime  \\\n",
       "0  Installing the game was a struggle (because of...   07 9, 2012   \n",
       "1  If you like rally cars get this game you will ...  06 30, 2013   \n",
       "2  1st shipment received a book instead of the ga...  06 28, 2014   \n",
       "3  I got this version instead of the PS3 version,...  09 14, 2011   \n",
       "4  I had Dirt 2 on Xbox 360 and it was an okay ga...  06 14, 2011   \n",
       "\n",
       "       reviewerID                        reviewerName  \\\n",
       "0  A2HD75EMZR8QLN                                 123   \n",
       "1  A3UR8NLLY1ZHCX  Alejandro Henao \"Electronic Junky\"   \n",
       "2  A1INA0F5CWW3J4          Amazon Shopper \"Mr.Repsol\"   \n",
       "3  A1DLMTOTHQ4AST                            ampgreen   \n",
       "4  A361M14PU2GUEG        Angry Ryan \"Ryan A. Forrest\"   \n",
       "\n",
       "                                           summary  unixReviewTime  \n",
       "0         Pay to unlock content? I don't think so.      1341792000  \n",
       "1                                  Good rally game      1372550400  \n",
       "2                                        Wrong key      1403913600  \n",
       "3  awesome game, if it did not crash frequently !!      1315958400  \n",
       "4                                           DIRT 3      1308009600  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews:Number 231780\n",
      "Number of 5 star reviews: 120185\n",
      "Number of 4 star reviews: 54804\n",
      "Number of 3 star reviews: 28275\n",
      "Number of 2 star reviews: 13663\n",
      "Number of 1 star reviews: 14853\n"
     ]
    }
   ],
   "source": [
    "print('Number of reviews:''Number',len(df.overall))\n",
    "print('Number of 5 star reviews:',sum(df.overall==5))\n",
    "print('Number of 4 star reviews:',sum(df.overall==4))\n",
    "print('Number of 3 star reviews:',sum(df.overall==3))\n",
    "print('Number of 2 star reviews:',sum(df.overall==2))\n",
    "print('Number of 1 star reviews:',sum(df.overall==1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the number of reviews, nearly half of them are 5-star and only about 6% of the reviews are 1 star. As I believe the negative reviews are just as important to a bussiness (because they offer constructive critism for growth) as positive reviews, I need to figure out how to balance these polar ratings. To help balance the good reviews with the bad reviews I will be combining the number of 1 and 2 star reviews into a single class. I will also be ignoring 3 and 4 star reviews. This leaves about 19.2% of the remaining reviews as negative and 80.8% of reviews as positive.\n",
    "\n",
    "Because my data is still severely imbalanced and I feel that negative reviews are important and helpful to both consumers and businesses than positive reviews, I will be using a weighted F-Score to evaluate my model. F-Score utilizes both precision and recall for its metric. The weighted portion will help take into account the limited supply of negative reviews.\n",
    "\n",
    "##### Recall\n",
    "A good recall is the ability to mark as many of the N-star reviews as a N-star rating. For example, if we were looking for all the 5-star reviews then a good recall would mark as many of them as 5-star as possible. Furthermore, a perfect recall model, when given a N-star rating, will identify every review that is an N-star rating. However, it should be noted that this does not mean that every N-star review that is marked as a N-star rating is infact an N-star rating. This part of the F-score is focused on reducing false negatives. In this case, good recall is the ability for the model to identify all N-star reviews as N-star ratings.\n",
    "\n",
    "\n",
    "###### Precision\n",
    "Precision compliments recall as it concerns whether the model was correct or not. For example, a model with high precision on a certain rating will be accurate when it claims that a review is that specific rating. Perfect precision means you can trust that the model knows when a \"duck is a duck\". However, precision does not concern iteself with ensuring that it identifies all the reviews correctly. In this case, good precision is the ability for the model to be correct when it claims a N-star review is an N-star rating. It is not concerned with catching all the reviews for a specific rating, only that when it determins a specific rating for a review, it is correct. This is important to this business case because we wouldn't want mislabeled reviews. Good reviews mislabled as bad reviews would waste the time of whomever was in charge of remiediating bad user experience for the video games. Not only that but bad reviews labeled good would be filtered out by the business as they would assume everything is doing ok when in reality there could be something terrible about a video game (bug or UX) situation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by getting rid of any nulls\n",
    "df = df[pd.notnull(df['overall'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing rating 2s with rating 1s\n",
    "# Also replacing 4s with 3 to remove later\n",
    "df.overall.replace([1, 2, 3, 4, 5], [1, 1, 3, 3, 5],\n",
    "                  inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing 3s and 4s from the datset\n",
    "df = df[df.overall != 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews:Number 148701\n",
      "Number of 5 star reviews: 120185      Percentage:  0.8082326278908682\n",
      "Number of 4 star reviews: 0\n",
      "Number of 3 star reviews: 0\n",
      "Number of 2 star reviews: 0\n",
      "Number of 1 star reviews: 28516      Percentage:  0.19176737210913175\n"
     ]
    }
   ],
   "source": [
    "print('Number of reviews:''Number',len(df.overall))\n",
    "print('Number of 5 star reviews:',sum(df.overall==5), '     Percentage: ', (sum(df.overall==5) / len(df.overall)))\n",
    "print('Number of 4 star reviews:',sum(df.overall==4))\n",
    "print('Number of 3 star reviews:',sum(df.overall==3))\n",
    "print('Number of 2 star reviews:',sum(df.overall==2))\n",
    "print('Number of 1 star reviews:',sum(df.overall==1), '     Percentage: ', (sum(df.overall==1) / len(df.overall)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing nearly half the data during pre-processing, I will need to utilize a test splitting method to accomadate the smaller subset of data. I have decided to use Stratified 10-fold cross validation for splitting my data into training and testing subsets. The advanatage of using this type of method is that all of the data is eventually used for both training and testing and it is only used once. Stratification ensures that each fold of my data is adaquently represented and is the correct proportion. \n",
    "\n",
    "Unfortunately I was unable to get stratified k fold to work. Although I don't believe train_test_split is the best choice, I do believe it will be effective during my validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Continued..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing I have done is change all rating 2 reviews to rating 1 reviews as they are both deemed negative. Next I removed all reviews that were not labled polar (1 or 5). I want to also convert this to binary as I believe it will be easier that way later on (0 for bad review, don't buy the game, 1 for good review, buy the game)\n",
    "\n",
    "I will also check (and remove if neccessary) if there are any duplicate reviews as this would falsely skew my validation later on. I will also remove any entrees that do not have a review as this would not help with my predicition task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.overall.replace([1, 5], [0, 1],\n",
    "                  inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Checking for dupplicate entrees by comparing the product ID with the reviewer ID. \n",
    "# Dupplicates would be from the same reviewer on the same product\n",
    "print(len(df[df.duplicated(['asin', 'reviewerID'])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148701"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are no dupplicates but we still need to make sure we don't have missing data for reviews\n",
    "#df.head()\n",
    "df = df[pd.notnull(df['reviewText'])]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets also get rid of some of the columns that we for sure don't need\n",
    "\n",
    "del df['reviewTime']\n",
    "del df['helpful']\n",
    "del df['unixReviewTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's convert the ratings to binary now\n",
    "df['overall'] = df['overall'].astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating (0-1): False\n",
      "Review:  This was on a shipment that was stolen in Venezuela, by the GNB officers in the customs area. The Venezuelan guar are just a bunch of thieves.\n"
     ]
    }
   ],
   "source": [
    "#Lets take a look at a random review\n",
    "random_index = np.random.choice(df.index)\n",
    "print('Rating (0-1):', + df.overall[random_index])\n",
    "print('Review: ',(df.reviewText[random_index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there weren't any empty reviews so we can move on to training. \n",
    "Below is a look at the final dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    asin: Product ID \n",
    "    helpful: Tuple containing the number of people who found the review helpful versus not helpful (deleted)\n",
    "    overall: The rating (0 or 1)\n",
    "    reviewText: The actual review\n",
    "    reviewTime: The timestamp of the review (deleted)\n",
    "    reviewerID: ID of the reviewer\n",
    "    reviewerName: The reviewer's name\n",
    "    summary: Summary of the review\n",
    "    unixReviewTime: Timestamp of the review (deleted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0700099867</td>\n",
       "      <td>0</td>\n",
       "      <td>Installing the game was a struggle (because of...</td>\n",
       "      <td>A2HD75EMZR8QLN</td>\n",
       "      <td>123</td>\n",
       "      <td>Pay to unlock content? I don't think so.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0700099867</td>\n",
       "      <td>0</td>\n",
       "      <td>1st shipment received a book instead of the ga...</td>\n",
       "      <td>A1INA0F5CWW3J4</td>\n",
       "      <td>Amazon Shopper \"Mr.Repsol\"</td>\n",
       "      <td>Wrong key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0700099867</td>\n",
       "      <td>1</td>\n",
       "      <td>Loved playing Dirt 2 and I thought the graphic...</td>\n",
       "      <td>AN3YYDZAS3O1Y</td>\n",
       "      <td>Bob</td>\n",
       "      <td>A step up from Dirt 2 and that is terrific!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0700099867</td>\n",
       "      <td>0</td>\n",
       "      <td>I can't tell you what a piece of dog**** this ...</td>\n",
       "      <td>AQTC623NCESZW</td>\n",
       "      <td>Chesty Puller</td>\n",
       "      <td>Crash 3 is correct name AKA Microsoft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0700099867</td>\n",
       "      <td>0</td>\n",
       "      <td>I still haven't figured this one out. Did ever...</td>\n",
       "      <td>A2JLT2WY0F2HVI</td>\n",
       "      <td>D. Sweetapple</td>\n",
       "      <td>Couldn't get this one to work</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  overall                                         reviewText  \\\n",
       "0  0700099867        0  Installing the game was a struggle (because of...   \n",
       "2  0700099867        0  1st shipment received a book instead of the ga...   \n",
       "6  0700099867        1  Loved playing Dirt 2 and I thought the graphic...   \n",
       "7  0700099867        0  I can't tell you what a piece of dog**** this ...   \n",
       "9  0700099867        0  I still haven't figured this one out. Did ever...   \n",
       "\n",
       "       reviewerID                reviewerName  \\\n",
       "0  A2HD75EMZR8QLN                         123   \n",
       "2  A1INA0F5CWW3J4  Amazon Shopper \"Mr.Repsol\"   \n",
       "6   AN3YYDZAS3O1Y                         Bob   \n",
       "7   AQTC623NCESZW               Chesty Puller   \n",
       "9  A2JLT2WY0F2HVI               D. Sweetapple   \n",
       "\n",
       "                                       summary  \n",
       "0     Pay to unlock content? I don't think so.  \n",
       "2                                    Wrong key  \n",
       "6  A step up from Dirt 2 and that is terrific!  \n",
       "7        Crash 3 is correct name AKA Microsoft  \n",
       "9                Couldn't get this one to work  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://stackoverflow.com/questions/43547402/how-to-calculate-f1-macro-in-keras# from h \n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 170399 unique tokens. Distilled to 170399 top words.\n"
     ]
    }
   ],
   "source": [
    "# Modified from https://github.com/eclarson/MachineLearningNotebooks/blob/master/13.%20RNN%20Basics.ipynb\n",
    "\n",
    "NUM_TOP_WORDS = None\n",
    "MAX_ART_LEN = 1000 # maximum and minimum number of words\n",
    "\n",
    "tokenizer = Tokenizer(num_words=NUM_TOP_WORDS)\n",
    "tokenizer.fit_on_texts(df.reviewText.values)\n",
    "sequences = tokenizer.texts_to_sequences(df.reviewText.values)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "NUM_TOP_WORDS = len(word_index) if NUM_TOP_WORDS==None else NUM_TOP_WORDS\n",
    "top_words = min((len(word_index),NUM_TOP_WORDS))\n",
    "print('Found %s unique tokens. Distilled to %d top words.' % (len(word_index),top_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (148701, 1000)\n",
      "Shape of label tensor: (148701, 2)\n",
      "170399\n"
     ]
    }
   ],
   "source": [
    "X = pad_sequences(sequences, maxlen=MAX_ART_LEN)\n",
    "y = dataframe['overall']\n",
    "\n",
    "y_ohe = keras.utils.to_categorical(y)\n",
    "print('Shape of data tensor:', X.shape)\n",
    "print('Shape of label tensor:', y_ohe.shape)\n",
    "print(np.max(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118960, 1000) (118960, 2)\n",
      "[22813. 96147.]\n"
     ]
    }
   ],
   "source": [
    "# Split it into train / test subsets\n",
    "X_train, X_test, y_train_ohe, y_test_ohe = train_test_split(X, y_ohe, test_size=0.2,\n",
    "                                                            stratify=df.overall, \n",
    "                                                            random_state=42)\n",
    "NUM_CLASSES = 20\n",
    "print(X_train.shape,y_train_ohe.shape)\n",
    "print(np.sum(y_train_ohe,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "(170400, 100)\n",
      "CPU times: user 10 s, sys: 342 ms, total: 10.4 s\n",
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# from https://github.com/eclarson/MachineLearningNotebooks/blob/master/13.%20RNN%20Basics.ipynb\n",
    "\n",
    "EMBED_SIZE = 100\n",
    "# the embed size should match the file you load glove from\n",
    "embeddings_index = {}\n",
    "f = open('../data/glove.6B.100d.txt')\n",
    "# save key/array pairs of the embeddings\n",
    "#  the key of the dictionary is the word, the array is the embedding\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "# now fill in the matrix, using the ordering from the\n",
    "#  keras word tokenizer from before\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBED_SIZE))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBED_SIZE,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_ART_LEN,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1000, 100)         17040000  \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 17,120,602\n",
      "Trainable params: 80,602\n",
      "Non-trainable params: 17,040,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# LSTM Model\n",
    "\n",
    "rnn = Sequential()\n",
    "rnn.add(embedding_layer)\n",
    "rnn.add(LSTM(100,dropout=0.2, recurrent_dropout=0.2))\n",
    "rnn.add(Dense(2, activation='sigmoid'))\n",
    "rnn.compile(loss='categorical_crossentropy', \n",
    "              optimizer='rmsprop', \n",
    "              metrics=['accuracy', f1])\n",
    "print(rnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 118960 samples, validate on 29741 samples\n",
      "Epoch 1/3\n",
      "118960/118960 [==============================] - 3284s 28ms/step - loss: 0.3495 - acc: 0.8522 - f1: 0.8353 - val_loss: 0.2329 - val_acc: 0.9037 - val_f1: 0.8806\n",
      "Epoch 2/3\n",
      "118960/118960 [==============================] - 3256s 27ms/step - loss: 0.2355 - acc: 0.9045 - f1: 0.8777 - val_loss: 0.2017 - val_acc: 0.9192 - val_f1: 0.9030\n",
      "Epoch 3/3\n",
      "118960/118960 [==============================] - 3224s 27ms/step - loss: 0.2072 - acc: 0.9172 - f1: 0.8772 - val_loss: 0.1796 - val_acc: 0.9269 - val_f1: 0.9032\n"
     ]
    }
   ],
   "source": [
    "history_rnn_lstm = rnn.fit(X_train, y_train_ohe, \n",
    "                           validation_data=(X_test, y_test_ohe), \n",
    "                           epochs=3, \n",
    "                           batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1000, 100)         17040000  \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 100)               60300     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 17,100,502\n",
      "Trainable params: 60,502\n",
      "Non-trainable params: 17,040,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# GRU Model\n",
    "\n",
    "rnn2 = Sequential()\n",
    "rnn2.add(embedding_layer)\n",
    "rnn2.add(GRU(100,dropout=0.2, recurrent_dropout=0.2))\n",
    "rnn2.add(Dense(2, activation='sigmoid'))\n",
    "rnn2.compile(loss='categorical_crossentropy', \n",
    "              optimizer='rmsprop', \n",
    "              metrics=['accuracy', f1])\n",
    "print(rnn2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 118960 samples, validate on 29741 samples\n",
      "Epoch 1/3\n",
      "118960/118960 [==============================] - 2904s 24ms/step - loss: 0.2994 - acc: 0.8770 - f1: 0.8002 - val_loss: 0.2075 - val_acc: 0.9164 - val_f1: 0.8317\n",
      "Epoch 2/3\n",
      "118960/118960 [==============================] - 2908s 24ms/step - loss: 0.2096 - acc: 0.9157 - f1: 0.7290 - val_loss: 0.1832 - val_acc: 0.9251 - val_f1: 0.7445\n",
      "Epoch 3/3\n",
      "118960/118960 [==============================] - 2895s 24ms/step - loss: 0.1861 - acc: 0.9266 - f1: 0.7250 - val_loss: 0.1713 - val_acc: 0.9313 - val_f1: 0.7837\n"
     ]
    }
   ],
   "source": [
    "history_rnn_gru = rnn2.fit(X_train, y_train_ohe, \n",
    "                           validation_data=(X_test, y_test_ohe), \n",
    "                           epochs=3, \n",
    "                           batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified from https://github.com/eclarson/MachineLearningNotebooks/blob/master/11.%20Convolutional%20Neural%20Networks.ipynb\n",
    "\n",
    "def confusion_rnn(rnn, X_test, y_test, title):\n",
    "#     plt.figure(figsize=(15,5))\n",
    "#     if rnn is not None:\n",
    "#         yhat = np.argmax(rnn.predict(X_test), axis=1)\n",
    "#         f1_rnn = mt.f1_score(y_test,yhat, average=\"macro\")\n",
    "#         acc_rnn = mt.accuracy_score(y_test,yhat)\n",
    "#         plt.subplot(1,2,1)\n",
    "#         cm = mt.confusion_matrix(y_test,yhat)\n",
    "#         cm = cm/np.sum(cm,axis=1)[:,np.newaxis]\n",
    "#         sns.heatmap(cm, annot=True, fmt='.2f')\n",
    "#         plt.title(str(title) + '   RNN_acc: '+str(acc_cnn) + '   RNN_F1: ' +str(f1_cnn))\n",
    "\n",
    "    yhat = np.argmax(rnn.predict(X_test), axis=1)\n",
    "    y_test = np.argmax(y_test_ohe, axis = 1)\n",
    "    cm = mt.confusion_matrix(y_test,yhat)\n",
    "    cm = cm/np.sum(cm,axis=1)[:,np.newaxis]\n",
    "    acc = mt.accuracy_score(y_test,yhat)\n",
    "    f1 = mt.f1_score(y_test,yhat, average=\"macro\")\n",
    "    plt.title(\"Using \" + str(title) + \": \" +' Acc: {:.4f}'.format(acc) + ' F1: {:.4f}'.format(f1))\n",
    "    sns.heatmap(cm, annot=True, fmt='.2f')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_rnn(rnn, X_test, y_test, 'lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_rnn(rnn2, X_test, y_test, 'GRU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
